# -*- coding: utf-8 -*-
"""covid_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G9JT_XrFiFWNiZ8r8qrfulD1WBeGubHt
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import Input, layers

import matplotlib.pyplot as plt
import numpy as np

#Create image data generators
training_data_generator = ImageDataGenerator(
    rescale = 1.0/255,
    zoom_range = 0.2,
    rotation_range = 15,
    width_shift_range = 0.05,
    height_shift_range = 0.05 
)

validating_data_generator = ImageDataGenerator(rescale = 1.0/255)

#Create iterators and import images

training_iterator = training_data_generator.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/ImageClassification/Covid19-dataset/train', color_mode='grayscale', batch_size=32, class_mode='categorical')

validating_iterator = validating_data_generator.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/ImageClassification/Covid19-dataset/test', color_mode='grayscale', batch_size=32, class_mode='categorical')

#Build the neural network model 

model = Sequential()
model.add(Input(shape=(255, 255, 1)))
model.add(layers.Conv2D(6, 4, strides=2, activation='relu'))
model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(3,3)))
model.add(layers.Conv2D(6, 4, strides=2, activation='relu'))
model.add(layers.MaxPooling2D(pool_size=(3,3), strides=(3,3)))
model.add(layers.Flatten())
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(8, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))

print(model.summary())
# No. of parameters = 7919

#Compile the model

model.compile(
    optimizer = Adam(learning_rate=0.01), 
    loss = tf.keras.losses.CategoricalCrossentropy(),
    metrics = [tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC()])

#Fit the model to train the data

model.fit(training_iterator,
          steps_per_epoch = training_iterator.samples//32,
          epochs = 10,
          validation_data = validating_iterator,
          validation_steps = validating_iterator.samples//32)

